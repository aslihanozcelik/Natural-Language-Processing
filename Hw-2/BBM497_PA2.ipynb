{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BBM497_PA2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOAfJMeh3gcE",
        "colab_type": "code",
        "outputId": "cd975a84-e17b-4e1a-a628-202ca2c1f81e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from collections import Counter\n",
        "import re\n",
        "import operator\n",
        "\n",
        "\n",
        "class HMM:\n",
        "    def __init__(self, initial_probabilities, transition_probabilities, emission_probabilities, initial_frequencies,\n",
        "                 transition_frequencies, emission_frequencies, all_tags, all_tags_and_counts):\n",
        "        self.initial_probabilities = initial_probabilities\n",
        "        self.transition_probabilities = transition_probabilities\n",
        "        self.emission_probabilities = emission_probabilities\n",
        "        self.initial_frequencies = initial_frequencies\n",
        "        self.transition_frequencies = transition_frequencies\n",
        "        self.emission_frequencies = emission_frequencies\n",
        "        self.alltags = all_tags\n",
        "        self.all_tags_and_counts = all_tags_and_counts\n",
        "\n",
        "    # This function takes path as an argument, reads and returns the list of sentences\n",
        "    def dataset(path):\n",
        "        with open(path) as f:\n",
        "            read_data = f.read()\n",
        "        # Split data into paragraphs\n",
        "        paragraphs = re.split('\\n\\n', read_data)\n",
        "        sentences = []\n",
        "        all_tags = []\n",
        "        for line in paragraphs:\n",
        "            # Split paragraphs into lines\n",
        "            lines = re.split('\\n', line)\n",
        "            sentence = ''\n",
        "            tag = ''\n",
        "            for word in lines:\n",
        "                # Split lines into words\n",
        "                words = re.split(' ', word)\n",
        "                if len(words) is 4:\n",
        "                    if words[0] != '-DOCSTART-':\n",
        "                        if path == '/content/drive/My Drive/497/train.txt':\n",
        "                            # Take first words from each lines, merge them with tags and create tagged sentences\n",
        "                            sentence = sentence + words[0].lower() + '|' + words[3] + ' '\n",
        "                        if path == '/content/drive/My Drive/497/test.txt':\n",
        "                            sentence = sentence + words[0].lower() + ' '\n",
        "                        all_tags.append(words[3])\n",
        "            # Remove spaces from the end of each sentence and store them in a list\n",
        "            if sentence != '':\n",
        "                sentences.append(sentence[:len(sentence) - 1])\n",
        "        HMM.all_tags_and_counts = dict(Counter(all_tags))\n",
        "        # Remove duplicates and store all tags in a list\n",
        "        alltags = list(dict.fromkeys(all_tags))\n",
        "        HMM.alltags = alltags\n",
        "        return sentences\n",
        "\n",
        "    # This function takes sentences and create HMM model.\n",
        "    # Returns initial, transition and emission probabilities of HMM model.\n",
        "    def hmm(sentences):\n",
        "        tags = []\n",
        "        tag_bigrams = []\n",
        "\n",
        "        all_words_with_tags = []    # All words and tags from train.txt (word | tag)\n",
        "        for sentence in sentences:\n",
        "            # Split each sentence into words\n",
        "            words = sentence.split(' ')\n",
        "            all_words_with_tags.extend(words)\n",
        "            all_tags = []\n",
        "            for i in range(0, len(words)):\n",
        "                y = words[i].split('|')\n",
        "                all_tags.append(y[1])\n",
        "                if i == 0:\n",
        "                  tags.append(y[1])\n",
        "            for j in range(0, len(words) - 1):\n",
        "                tag_bigrams.append(all_tags[j + 1] + \"|\" + all_tags[j])\n",
        "\n",
        "\n",
        "        initial_sum = len(tags)\n",
        "\n",
        "        # ---FREQUENCY LISTS FOR CALCULATE INITIAL, TRANSITION AND EMISSION PROBABILITIES---\n",
        "\n",
        "        # I keep first tags of sentences and their frequencies in a dictionary\n",
        "        HMM.initial_frequencies = dict(Counter(tags))\n",
        "\n",
        "        # I keep the frequencies of the tags coming after another tag (bigram) in a dictionary\n",
        "        HMM.transition_frequencies = dict(Counter(tag_bigrams))\n",
        "\n",
        "        # I keep word - tag pairs and their frequencies in a dictionary\n",
        "        HMM.emission_frequencies = dict(Counter(all_words_with_tags))\n",
        "\n",
        "        initial_probabilities = {}\n",
        "        transition_probabilities = {}\n",
        "        emission_probabilities = {}\n",
        "\n",
        "        # INITIAL PROBABILITY IS BEING CALCULATED\n",
        "        for key in HMM.initial_frequencies:\n",
        "            initial_probabilities[key] = float(HMM.initial_frequencies[key] / initial_sum)\n",
        "\n",
        "        # TRANSITION PROBABILITY IS BEING CALCULATED\n",
        "        for key in HMM.transition_frequencies:\n",
        "            tags = key.split('|')\n",
        "            transition_probabilities[key] = float(HMM.transition_frequencies[key] / HMM.all_tags_and_counts[tags[1]])\n",
        " \n",
        "        # EMISSION PROBABILITY IS BEING CALCULATED\n",
        "        for key in HMM.emission_frequencies:\n",
        "            tags = key.split('|')\n",
        "            emission_probabilities[key] = float(HMM.emission_frequencies[key] / HMM.all_tags_and_counts[tags[1]])\n",
        "\n",
        "\n",
        "\n",
        "        return initial_probabilities, transition_probabilities, emission_probabilities\n",
        "\n",
        "    # This function takes test sentences and apply Viterbi Algorithm on them.\n",
        "    # Then returns the tagged test sentences.\n",
        "\n",
        "    def viterbi(sentences):\n",
        "\n",
        "        sentences_with_tags = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_with_tags = ''\n",
        "            # Split each sentence into words\n",
        "            words = sentence.split(' ')\n",
        "            rows = len(HMM.alltags)\n",
        "            columns = len(words)\n",
        "            # Fills whole matrix with 1's\n",
        "            viterbi_matrix = [[1 for x in range(0, columns)] for y in range(0, rows)]\n",
        "\n",
        "            # Fills the first column of the matrix with initial probabilities * emission probabilities\n",
        "            for i in range(0, rows):\n",
        "                # Checking emission probability existence in HMM Model \n",
        "                try:\n",
        "                    emission = HMM.emission_probabilities[words[0] + '|' + HMM.alltags[i]]\n",
        "                    viterbi_matrix[i][0] = float(float(HMM.initial_probabilities[HMM.alltags[i]]) * float(emission))\n",
        "                except:\n",
        "                    emission = 0\n",
        "                    viterbi_matrix[i][0] = float(emission)\n",
        "\n",
        "            transitions = {}\n",
        "            if columns > 1:\n",
        "                for j in range(1, columns):\n",
        "                    for i in range(0, rows):\n",
        "                        # Checking emission probability existence in HMM Model\n",
        "                        try:\n",
        "                            # Getting emission probability from HMM Model for current word and tag\n",
        "                            emission = HMM.emission_probabilities[words[j] + '|' + HMM.alltags[i]]\n",
        "                        # If there is no emission probability in HMM Model, Smoothing algorithm not applied.\n",
        "                        except:\n",
        "                            emission = 0\n",
        "                        for k in range(0, rows):\n",
        "                            # Checking transition probability existence in HMM Model\n",
        "                            try:\n",
        "                                # For each tag we multiply emission probability,transition probability and  previous probabilities\n",
        "                                # Then we take the maximum of these probabilities for each tag\n",
        "                                transitions[k] = HMM.transition_probabilities[HMM.alltags[k] + '|' + HMM.alltags[i]] * emission * viterbi_matrix[k][j - 1]\n",
        "                            # If transition probability does not exists in HMM Model Laplace smoothing applied\n",
        "                            except:\n",
        "                                transitions[k] = (1 / ((HMM.all_tags_and_counts[HMM.alltags[i]] + 1))) * emission * viterbi_matrix[k][j - 1]\n",
        "                                \n",
        "                        max_transition_index = max(transitions.items(), key=operator.itemgetter(1))[0]\n",
        "                        # We take the maximum probabilities for each tag and add them to our matrix\n",
        "                        viterbi_matrix[i][j] = transitions[max_transition_index]\n",
        "\n",
        "            maxs = []\n",
        "            index = 0\n",
        "            all_columns = {}\n",
        "            for j in range(0, columns):\n",
        "                each_column = []\n",
        "                for i in range(0, rows):\n",
        "                    each_column.append(viterbi_matrix[i][j])\n",
        "                all_columns[j] = each_column\n",
        "                element = max(all_columns[j])\n",
        "                maxs.append(each_column.index(element))\n",
        "            # Predicted tags are added to the test sentences\n",
        "            for i in maxs:\n",
        "                sentence_with_tags = sentence_with_tags + (words[index] + '|' + HMM.alltags[i] + ' ')\n",
        "                index = index + 1\n",
        "\n",
        "            sentences_with_tags.append(sentence_with_tags)\n",
        "\n",
        "        return sentences_with_tags\n",
        "\n",
        "    # It takes gold sequences and predicted sequences and returns the accuracy\n",
        "    def accuracy(gold_sequences, predicted_sequences):\n",
        "        total_words = 0\n",
        "        correct_found_tags = 0\n",
        "        for i in range(0, len(gold_sequences)):\n",
        "            gold_words = gold_sequences[i].split(' ')\n",
        "            predicted_words = predicted_sequences[i].split(' ')\n",
        "            for j in range(0, len(gold_words)):\n",
        "                if gold_words[j] == predicted_words[j]:\n",
        "                    total_words = total_words + 1\n",
        "                    correct_found_tags = correct_found_tags + 1\n",
        "                else:\n",
        "                    total_words = total_words + 1\n",
        "\n",
        "        return correct_found_tags / total_words\n",
        "\n",
        "# Reread test.txt to obtain gold_sequence\n",
        "def read_sentences(path):\n",
        "    with open(path) as f:\n",
        "        read_data = f.read()\n",
        "        paragraphs = re.split('\\n\\n', read_data)  # split data into paragraphs\n",
        "        sentences = []\n",
        "        for line in paragraphs:\n",
        "            lines = re.split('\\n', line)  # split paragraphs into lines\n",
        "            sentence = ''\n",
        "            tag = ''\n",
        "\n",
        "            for word in lines:\n",
        "                words = re.split(' ', word)  # split lines into words\n",
        "                if len(words) is 4:\n",
        "                    if words[0] != '-DOCSTART-':\n",
        "                        sentence = sentence + words[0].lower() + '|' + words[3] + ' '\n",
        "            if sentence != '':\n",
        "                sentences.append(sentence[:len(sentence) - 1])\n",
        "    return sentences\n",
        "\n",
        "\n",
        "sentences = HMM.dataset(\"/content/drive/My Drive/497/train.txt\")\n",
        "\n",
        "HMM.initial_probabilities, HMM.transition_probabilities, HMM.emission_probabilities = HMM.hmm(sentences)\n",
        "\n",
        "test_sentences = HMM.dataset('/content/drive/My Drive/497/test.txt')\n",
        "\n",
        "predicted_sentences = HMM.viterbi(test_sentences)\n",
        "\n",
        "test_sentences_with_tags = read_sentences('/content/drive/My Drive/497/test.txt')\n",
        "\n",
        "accuracy = HMM.accuracy(test_sentences_with_tags, predicted_sentences)\n",
        "print(\"Accuracy is  : \" + str(accuracy))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy is  : 0.7506535947712418\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3IoKiZ34GgG",
        "colab_type": "code",
        "outputId": "12af4e24-25a7-4896-9cf1-c61cfa3e4bcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}